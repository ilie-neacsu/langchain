{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-Models App"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df18acbc22cfa1c0"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in ./.venv/lib/python3.11/site-packages (0.18.0)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (3.12.4)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (2023.9.2)\r\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (4.66.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (4.8.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface_hub) (23.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.3.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2.0.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2023.7.22)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:42:44.235563Z",
     "start_time": "2023-10-21T15:42:42.461117Z"
    }
   },
   "id": "2d104bf2051e1a90"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import HuggingFaceHub\n",
    "from getpass import getpass\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain import PromptTemplate, LLMChain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:42:45.355072Z",
     "start_time": "2023-10-21T15:42:44.235046Z"
    }
   },
   "id": "31ddef851791d6f7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:42:45.360705Z",
     "start_time": "2023-10-21T15:42:45.355896Z"
    }
   },
   "id": "5d7889671fdf77ef"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:42:45.361004Z",
     "start_time": "2023-10-21T15:42:45.359386Z"
    }
   },
   "id": "cef0a0c6f5d95346"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "repo_id = \"google/flan-t5-xxl\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:42:45.365967Z",
     "start_time": "2023-10-21T15:42:45.361428Z"
    }
   },
   "id": "5a4723c8b1db333b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "openai_llm = ChatOpenAI(openai_api_key=openai.api_key, model_name='gpt-3.5-turbo', max_tokens=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:42:45.366375Z",
     "start_time": "2023-10-21T15:42:45.364156Z"
    }
   },
   "id": "a5c2213d21629139"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ineacsu/source/courses/pluralsight/langchain/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "flan_llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={ \"max_length\": 100 })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:42:47.134797Z",
     "start_time": "2023-10-21T15:42:45.366949Z"
    }
   },
   "id": "10cbed92733e42c8"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def openai_process(question):\n",
    "    reply = openai_llm([\n",
    "        SystemMessage(content='You are a helpful assistant'),\n",
    "        HumanMessage(content=question)\n",
    "    ])\n",
    "    return reply.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:54:19.673545Z",
     "start_time": "2023-10-21T15:54:19.665464Z"
    }
   },
   "id": "16f90e1f1c0d9426"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def flan_process(question):\n",
    "    template = '{question}'\n",
    "    prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "    llm_chain = LLMChain(llm=flan_llm, prompt=prompt)\n",
    "    return llm_chain(question)['text']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:54:43.172317Z",
     "start_time": "2023-10-21T15:54:43.168283Z"
    }
   },
   "id": "d2a21d5e7b02db34"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI reply: The capital of France is Paris.\n",
      "Flan reply: paris\n"
     ]
    }
   ],
   "source": [
    "question = 'What is the capital of France?'\n",
    "openai_reply = openai_process(question)\n",
    "print(f\"OpenAI reply: {openai_reply}\")\n",
    "flan_reply = flan_process(question)\n",
    "print(f\"Flan reply: {flan_reply}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T15:55:56.223248Z",
     "start_time": "2023-10-21T15:55:53.276173Z"
    }
   },
   "id": "7693516749fbd13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f8cc951054e942d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
